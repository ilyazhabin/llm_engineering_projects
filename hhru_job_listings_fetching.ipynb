{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019974d9-f3ad-4a8a-b5f9-0a3719aea2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069584e5-62a3-4798-b66d-75cff5cc8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "HH_API_BASE_URL = \"https://api.hh.ru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65cf847a-384d-4fd1-9a45-7fb234638f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://api.hh.ru\"\n",
    "\n",
    "def fetch_jobs(text=None, area=1, count=10) -> List[Dict]:\n",
    "    if not text:\n",
    "        text = \"ML OR Machine Learning OR LLM OR RAG OR LoRA OR Data Scientist OR AI OR GPT\"\n",
    "\n",
    "    url = f\"{BASE_URL}/vacancies\"\n",
    "    params = {\n",
    "        \"text\": text,\n",
    "        \"area\": area,\n",
    "        \"per_page\": min(count, 100),\n",
    "        \"professional_role\": [164, 165, 96],  # ML, DS\n",
    "        \"page\": 0,\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    items = response.json().get(\"items\", [])[:count]\n",
    "\n",
    "    job_descriptions = []\n",
    "    for vacancy in items:\n",
    "        vacancy_id = vacancy.get(\"id\")\n",
    "        detail_resp = requests.get(f\"{BASE_URL}/vacancies/{vacancy_id}\")\n",
    "        if detail_resp.status_code != 200:\n",
    "            continue\n",
    "\n",
    "        detail = detail_resp.json()\n",
    "        raw_description = detail.get(\"description\", \"\")\n",
    "        cleaned_description = clean_html(raw_description).strip()\n",
    "\n",
    "        if not cleaned_description:\n",
    "            continue\n",
    "\n",
    "        job_descriptions.append({\n",
    "            \"name\": detail.get(\"name\", \"No title\"),\n",
    "            \"description\": cleaned_description\n",
    "        })\n",
    "\n",
    "    return job_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cc9d6f5-0a6d-4bdc-a28c-277bea678507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def extract_keywords_from_jobs(jobs) -> dict:\n",
    "    results = {}\n",
    "\n",
    "    for job in jobs:\n",
    "        prompt = f\"\"\"\n",
    "You are given a job posting. Extract keywords ONLY in these 4 categories:\n",
    "\n",
    "- programming languages\n",
    "- databases\n",
    "- tools\n",
    "- job title\n",
    "\n",
    "Return the output in this format:\n",
    "{{\n",
    "  \"job title\": \"...\",\n",
    "  \"programming languages\": [...],\n",
    "  \"databases\": [...],\n",
    "  \"tools\": [...]\n",
    "}}\n",
    "\n",
    "Job posting:\n",
    "Title: {job['name']}\n",
    "Description:\n",
    "{job['description']}\n",
    "\"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts structured keyword data from job descriptions.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            result_text = response.choices[0].message.content.strip()\n",
    "            results[job['name']] = result_text\n",
    "        except Exception as e:\n",
    "            results[job['name']] = f\"‚ö†Ô∏è Error parsing result: {e}\"\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1130b2f7-2664-4fa2-8e26-520c1b2bcfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching job postings from HH.ru...\n",
      "‚úÖ 10 job postings fetched.\n",
      "- Frontend-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ (React): 2220 characters\n",
      "- Frontend-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫: 2130 characters\n",
      "- Data Scientist: 3978 characters\n",
      "- Middle data scientist (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π ml): 1888 characters\n",
      "- –ü—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç —Å –æ–±—É—á–µ–Ω–∏–µ–º: 1955 characters\n",
      "- Junior Data Scientist: 1831 characters\n",
      "- Middle Java Developer: 2201 characters\n",
      "- Python ML Engineer: 3066 characters\n",
      "- ML-–∏–Ω–∂–µ–Ω–µ—Ä (Classic ML, CVM): 2880 characters\n",
      "- Quantitative researcher / –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å-–∞–Ω–∞–ª–∏—Ç–∏–∫ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã): 2611 characters\n",
      "Sending each job to OpenAI for keyword extraction...\n",
      "\n",
      "‚úÖ Extracted Keywords Per Job:\n",
      "\n",
      "üß© Frontend-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ (React):\n",
      "{\n",
      "  \"job title\": \"Frontend-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫\",\n",
      "  \"programming languages\": [\"TypeScript\", \"JavaScript\", \"React\"],\n",
      "  \"databases\": [],\n",
      "  \"tools\": [\"React.js\", \"Redux\", \"RTK\", \"Linux\", \"Docker\", \"GitLab\", \"Jira\", \"Confluence\", \"vite\", \"webpack\", \"grpc\", \"jest\", \"vitest\"]\n",
      "}\n",
      "\n",
      "üß© Frontend-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫:\n",
      "{\n",
      "  \"job title\": \"Frontend-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫\",\n",
      "  \"programming languages\": [\"JavaScript\", \"HTML\", \"CSS\", \"TypeScript\"],\n",
      "  \"databases\": [],\n",
      "  \"tools\": [\"React\", \"Zustand\", \"Redux\", \"apollo\", \"REST\", \"GraphQL\", \"react-query\", \"swr\", \"Webpack\", \"Vite\", \"Docker\", \"Docker Compose\", \"tauri\", \"electronjs\", \"Leaflet\", \"Unix\"]\n",
      "}\n",
      "\n",
      "üß© Data Scientist:\n",
      "{\n",
      "  \"job title\": \"Data Scientist\",\n",
      "  \"programming languages\": [\"Python\"],\n",
      "  \"databases\": [],\n",
      "  \"tools\": [\"pandas\", \"NumPy\", \"scikit-learn\", \"PyTorch\", \"TensorFlow\", \"DEAP\", \"Plotly\", \"matplotlib\", \"seaborn\", \"Dash\", \"Streamlit\", \"Power BI\", \"Tableau\", \"Git\"]\n",
      "}\n",
      "\n",
      "üß© Middle data scientist (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π ml):\n",
      "{\n",
      "  \"job title\": \"Middle data scientist (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π ml)\",\n",
      "  \"programming languages\": [\"Python\"],\n",
      "  \"databases\": [\"SQL\", \"Oracle\", \"PL/SQL\", \"Hadoop\", \"SAS\"],\n",
      "  \"tools\": [\"ML-–º–æ–¥–µ–ª–∏\", \"SAS\"]\n",
      "}\n",
      "\n",
      "üß© –ü—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç —Å –æ–±—É—á–µ–Ω–∏–µ–º:\n",
      "{\n",
      "  \"job title\": \"–ü—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç —Å –æ–±—É—á–µ–Ω–∏–µ–º\",\n",
      "  \"programming languages\": [\"Python\"],\n",
      "  \"databases\": [\"SQL\"],\n",
      "  \"tools\": []\n",
      "}\n",
      "\n",
      "üß© Junior Data Scientist:\n",
      "{\n",
      "  \"job title\": \"Junior Data Scientist\",\n",
      "  \"programming languages\": [\"Python\"],\n",
      "  \"databases\": [\"SQL\"],\n",
      "  \"tools\": [\"numpy\", \"pandas\", \"sklearn\", \"plotly\", \"matplotlib\", \"seaborn\"]\n",
      "}\n",
      "\n",
      "üß© Middle Java Developer:\n",
      "{\n",
      "  \"job title\": \"Middle Java Developer\",\n",
      "  \"programming languages\": [\"Java\"],\n",
      "  \"databases\": [\"Apache Cassandra\"],\n",
      "  \"tools\": [\"Apache Kafka\", \"Docker\", \"Kubernetes\", \"Google Cloud Platform\", \"Spring Framework\", \"Spring Boot\", \"Spring WebFlux\", \"Gradle\"]\n",
      "}\n",
      "\n",
      "üß© Python ML Engineer:\n",
      "{\n",
      "  \"job title\": \"Python ML Engineer\",\n",
      "  \"programming languages\": [\"Python\"],\n",
      "  \"databases\": [\"SQL\"],\n",
      "  \"tools\": [\"TensorFlow\", \"PyTorch\", \"Scikit-learn\", \"XGBoost\", \"LangChain\", \"Pandas\", \"NumPy\", \"Spark\"]\n",
      "}\n",
      "\n",
      "üß© ML-–∏–Ω–∂–µ–Ω–µ—Ä (Classic ML, CVM):\n",
      "{\n",
      "  \"job title\": \"ML-–∏–Ω–∂–µ–Ω–µ—Ä\",\n",
      "  \"programming languages\": [\"Python\"],\n",
      "  \"databases\": [\"SQL\", \"NoSQL\"],\n",
      "  \"tools\": [\"Scikit-learn\", \"Pandas\", \"NumPy\", \"Docker\", \"Kubernetes\", \"MLflow\", \"Jira\", \"Confluence\"]\n",
      "}\n",
      "\n",
      "üß© Quantitative researcher / –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å-–∞–Ω–∞–ª–∏—Ç–∏–∫ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã):\n",
      "{\n",
      "  \"job title\": \"Quantitative researcher / –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å-–∞–Ω–∞–ª–∏—Ç–∏–∫\",\n",
      "  \"programming languages\": [\"Python\"],\n",
      "  \"databases\": [],\n",
      "  \"tools\": [\"Pandas\", \"NumPy\", \"SciPy\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"Fetching job postings from HH.ru...\")\n",
    "    jobs = fetch_jobs(text=\"–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\", count=10)\n",
    "\n",
    "    print(f\"‚úÖ {len(jobs)} job postings fetched.\")\n",
    "    for job in jobs:\n",
    "        print(f\"- {job['name']}: {len(job['description'])} characters\")\n",
    "\n",
    "    print(\"Sending each job to OpenAI for keyword extraction...\")\n",
    "    per_job_keywords = extract_keywords_from_jobs(jobs)\n",
    "\n",
    "    print(\"\\n‚úÖ Extracted Keywords Per Job:\")\n",
    "    for job_title, keywords in per_job_keywords.items():\n",
    "        print(f\"\\nüß© {job_title}:\\n{keywords}\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
